
DBManager.py

    1. 기존에 있던 코드들을 정리하고 필요 없다고 생각한 함수를 불용처리함

    2. 쿼리 실행 단계에서 cursor.close()를 실행하도록 변경함

    3. 함수에 SQL injection 방지 추가

        execute(sql, value) 따로 집어넣어서 자동으로 처리됨
        pymysql(.converter).escape_string(sql) 은 사용 안됨; 이유가...?

===========================================================================================

discussion_list_crawling.py

    1. 링크가 필요한가? 새로운 글이 작성되면 페이지가 밀림 > 이전에 저장한 링크가 필요 없어짐

        URL에서 nid가 있다면 그 뒷 줄은 필요없음. 크롤링 해오는 주소를 보완하고 뒷쪽을 지워버림
        이후 게시글을 크롤링 해오는 과정에서 사용할 수 있는 URL을 완성함

    2. 아직 다수의 데이터를 집어넣는 테스트는 안해봄

        해볼것

===========================================================================================

discussion_post_crawling.py

    1. 데이터베이스에서 테이블 설계가 복잡함

        복잡하지만 최대한 단순화 하는중. 테이블 하나로 끝내는 방법도 고려중임
        disc_analysis _cont 컬럼은 left(~_cont, N)으로 잘라보기 필수

    2. 병렬처리(스레드)를 도입해서 크롤링에 걸리는 시간 단축

        완벽히 이해하지는 못했으나 하나의 웹 드라이버로 10개의 스레드를 동시에 처리함
        다른 파일에서도 최적화하는 방법을 찾아서 도입하면 로딩 시간을 줄일 수 있을듯

    3. 게시글 삭제가 빈번함

        같은 날짜를 하루 뒤에 수집하니 99개 -> 89개로 10개가 감소함
        수집한 link 데이터가 필요없어지는 경우가 발생하여 failed_url 리스트 만듦
        수집하는 데이터보다도 나중에 보여질 데이터의 신뢰성에 영향을 미칠 수도 있을듯 싶음

        해결하기 위해서 변동이 적은 과거의 데이터를 수집한다면?
        일주일에서 한달 전 데이터는 변동이 적을 것으로 예상하지만,
        그만큼 최신의 심리지수는 파악할 수 없다는 맹점이 있음

        그럼 한달간의 데이터만 가지고 쓴다면?
        데이터가 쌓이는 형식이 아니라 한개의 데이터가 들어오면 한개의 데이터가 나가는 형식
        30일분의 데이터만 가지고 매일매일 30일분의 데이터를 갱신한다면 어떨까?